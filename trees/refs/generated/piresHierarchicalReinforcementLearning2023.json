[{"DOI": "10.48550/arXiv.2302.14451", "URL": "https://arxiv.org/abs/2302.14451", "abstract": "Hierarchical Reinforcement Learning (HRL) agents have the potential to demonstrate appealing capabilities such as planning and exploration with abstraction, transfer, and skill reuse. Recent successes with HRL across different domains provide evidence that practical, effective HRL agents are possible, even if existing agents do not yet fully realize the potential of HRL. Despite these successes, visually complex partially observable 3D environments remained a challenge for HRL agents. We address this issue with Hierarchical Hybrid Offline-Online (H2O2), a hierarchical deep reinforcement learning agent that discovers and learns to use options from scratch using its own experience. We show that H2O2 is competitive with a strong non-hierarchical Muesli baseline in the DeepMind Hard Eight tasks and we shed new light on the problem of learning hierarchical agents in complex environments. Our empirical study of H2O2 reveals previously unnoticed practical challenges and brings new perspective to the current understanding of hierarchical agents in complex domains.", "accessed": {"date-parts": [[2025, 2, 3]]}, "author": [{"family": "Pires", "given": "Bernardo Avila"}, {"family": "Behbahani", "given": "Feryal"}, {"family": "Soyer", "given": "Hubert"}, {"family": "Nikiforou", "given": "Kyriacos"}, {"family": "Keck", "given": "Thomas"}, {"family": "Singh", "given": "Satinder"}], "id": "piresHierarchicalReinforcementLearning2023", "issued": {"date-parts": [[2023, 2]]}, "keyword": "Computer Science - Artificial Intelligence,Computer Science - Machine Learning", "language": "en-US", "number": "arXiv:2302.14451", "publisher": "arXiv", "title": "Hierarchical Reinforcement Learning in Complex 3D Environments", "type": "", "original_bibtex": "@misc{piresHierarchicalReinforcementLearning2023,\n title = {Hierarchical {{Reinforcement Learning}} in {{Complex 3D Environments}}},\n author = {Pires, Bernardo Avila and Behbahani, Feryal and Soyer, Hubert and Nikiforou, Kyriacos and Keck, Thomas and Singh, Satinder},\n year = {2023},\n doi = {10.48550/arXiv.2302.14451},\n urldate = {2025-02-03},\n number = {arXiv:2302.14451},\n publisher = {arXiv},\n file = {/home/kellen/Zotero/storage/E6YDS983/Pires et al. - 2023 - Hierarchical Reinforcement Learning in Complex 3D Environments.pdf},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {Hierarchical Reinforcement Learning (HRL) agents have the potential to demonstrate appealing capabilities such as planning and exploration with abstraction, transfer, and skill reuse. Recent successes with HRL across different domains provide evidence that practical, effective HRL agents are possible, even if existing agents do not yet fully realize the potential of HRL. Despite these successes, visually complex partially observable 3D environments remained a challenge for HRL agents. We address this issue with Hierarchical Hybrid Offline-Online (H2O2), a hierarchical deep reinforcement learning agent that discovers and learns to use options from scratch using its own experience. We show that H2O2 is competitive with a strong non-hierarchical Muesli baseline in the DeepMind Hard Eight tasks and we shed new light on the problem of learning hierarchical agents in complex environments. Our empirical study of H2O2 reveals previously unnoticed practical challenges and brings new perspective to the current understanding of hierarchical agents in complex domains.},\n primaryclass = {cs},\n eprint = {2302.14451},\n month = {February}\n}\n"}]