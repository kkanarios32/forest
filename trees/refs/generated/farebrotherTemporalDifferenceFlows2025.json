[{"DOI": "10.48550/arXiv.2503.09817", "URL": "https://arxiv.org/abs/2503.09817", "abstract": "Predictive models of the future are fundamental for an agent\u2019s ability to reason and plan. A common strategy learns a world model and unrolls it step-by-step at inference, where small errors can rapidly compound. Geometric Horizon Models (GHMs) offer a compelling alternative by directly making predictions of future states, avoiding cumulative inference errors. While GHMs can be conveniently learned by a generative analog to temporal difference (TD) learning, existing methods are negatively affected by bootstrapping predictions at train time and struggle to generate high-quality predictions at long horizons. This paper introduces Temporal Difference Flows (TD-Flow), which leverages the structure of a novel Bellman equation on probability paths alongside flow-matching techniques to learn accurate GHMs at over 5x the horizon length of prior methods. Theoretically, we establish a new convergence result and primarily attribute TD-Flow\u2019s efficacy to reduced gradient variance during training. We further show that similar arguments can be extended to diffusion-based methods. Empirically, we validate TD-Flow across a diverse set of domains on both generative metrics and downstream tasks including policy evaluation. Moreover, integrating TD-Flow with recent behavior foundation models for planning over pre-trained policies demonstrates substantial performance gains, underscoring its promise for long-horizon decision-making.", "accessed": {"date-parts": [[2025, 6, 14]]}, "author": [{"family": "Farebrother", "given": "Jesse"}, {"family": "Pirotta", "given": "Matteo"}, {"family": "Tirinzoni", "given": "Andrea"}, {"family": "Munos", "given": "R\u00e9mi"}, {"family": "Lazaric", "given": "Alessandro"}, {"family": "Touati", "given": "Ahmed"}], "id": "farebrotherTemporalDifferenceFlows2025", "issued": {"date-parts": [[2025, 3]]}, "keyword": "Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning", "number": "arXiv:2503.09817", "publisher": "arXiv", "title": "Temporal Difference Flows", "type": "", "original_bibtex": "@misc{farebrotherTemporalDifferenceFlows2025,\n title = {Temporal {{Difference Flows}}},\n author = {Farebrother, Jesse and Pirotta, Matteo and Tirinzoni, Andrea and Munos, R{\\'e}mi and Lazaric, Alessandro and Touati, Ahmed},\n year = {2025},\n doi = {10.48550/arXiv.2503.09817},\n urldate = {2025-06-14},\n number = {arXiv:2503.09817},\n publisher = {arXiv},\n file = {/home/kellen/Zotero/storage/2V2SR66H/Farebrother et al. - 2025 - Temporal Difference Flows.pdf;/home/kellen/Zotero/storage/D27PSL2L/2503.html},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},\n archiveprefix = {arXiv},\n abstract = {Predictive models of the future are fundamental for an agent's ability to reason and plan. A common strategy learns a world model and unrolls it step-by-step at inference, where small errors can rapidly compound. Geometric Horizon Models (GHMs) offer a compelling alternative by directly making predictions of future states, avoiding cumulative inference errors. While GHMs can be conveniently learned by a generative analog to temporal difference (TD) learning, existing methods are negatively affected by bootstrapping predictions at train time and struggle to generate high-quality predictions at long horizons. This paper introduces Temporal Difference Flows (TD-Flow), which leverages the structure of a novel Bellman equation on probability paths alongside flow-matching techniques to learn accurate GHMs at over 5x the horizon length of prior methods. Theoretically, we establish a new convergence result and primarily attribute TD-Flow's efficacy to reduced gradient variance during training. We further show that similar arguments can be extended to diffusion-based methods. Empirically, we validate TD-Flow across a diverse set of domains on both generative metrics and downstream tasks including policy evaluation. Moreover, integrating TD-Flow with recent behavior foundation models for planning over pre-trained policies demonstrates substantial performance gains, underscoring its promise for long-horizon decision-making.},\n primaryclass = {cs},\n eprint = {2503.09817},\n month = {March}\n}\n"}]