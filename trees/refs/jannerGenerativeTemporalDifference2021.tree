\title{Generative Temporal Difference Learning for Infinite-Horizon Prediction}
\date{2021-11}
\taxon{Reference}
\meta{doi}{10.48550/arXiv.2010.14496}
\meta{external}{https://arxiv.org/abs/2010.14496}

\meta{bibtex}{\startverb
@misc{jannerGenerativeTemporalDifference2021,
 title = {Generative {{Temporal Difference Learning}} for {{Infinite-Horizon Prediction}}},
 author = {Janner, Michael and Mordatch, Igor and Levine, Sergey},
 year = {2021},
 doi = {10.48550/arXiv.2010.14496},
 urldate = {2025-05-13},
 number = {arXiv:2010.14496},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/UIRGT6ZE/Janner et al. - 2021 - Generative Temporal Difference Learning for Infinite-Horizon Prediction.pdf;/home/kellen/Downloads/pdfs/storage/53S6YNYL/2010.html},
 keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
 archiveprefix = {arXiv},
 abstract = {We introduce the \${\textbackslash}gamma\$-model, a predictive model of environment dynamics with an infinite probabilistic horizon. Replacing standard single-step models with \${\textbackslash}gamma\$-models leads to generalizations of the procedures central to model-based control, including the model rollout and model-based value estimation. The \${\textbackslash}gamma\$-model, trained with a generative reinterpretation of temporal difference learning, is a natural continuous analogue of the successor representation and a hybrid between model-free and model-based mechanisms. Like a value function, it contains information about the long-term future; like a standard predictive model, it is independent of task reward. We instantiate the \${\textbackslash}gamma\$-model as both a generative adversarial network and normalizing flow, discuss how its training reflects an inescapable tradeoff between training-time and testing-time compounding errors, and empirically investigate its utility for prediction and control.},
 primaryclass = {cs},
 eprint = {2010.14496},
 month = {November}
}
\stopverb}