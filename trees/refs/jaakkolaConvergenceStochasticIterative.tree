% ["refs"]
\title{On the Convergence of Stochastic Iterative Dynamic Programming Algorithms}
\author/literal{Tommi Jaakkola}\author/literal{Michael I Jordan}\author/literal{Satinder P Singh}
\taxon{Reference}
\meta{bibtex}{\startverb
@article{jaakkolaConvergenceStochasticIterative,
 title = {On the {{Convergence}} of {{Stochastic Iterative Dynamic Programming Algorithms}}},
 author = {Jaakkola, Tommi and Jordan, Michael I and Singh, Satinder P},
 file = {/home/kellen/Downloads/pdfs/storage/95ZWX95X/Jaakkola et al. - On the Convergence of Stochastic Iterative Dynamic Programming Algorithms.pdf},
 langid = {english},
 abstract = {Recent developments in the area of reinforcement learning have yielded a number of new algorithms for the prediction and control of Markovian environments. These algorithms, including the TD( ) algorithm of Sutton (1988) and the Q-learning algorithm of Watkins (1989), can be motivated heuristically as approximations to dynamic programming (DP). In this paper we provide a rigorous proof of convergence of these DP-based learning algorithms by relating them to the powerful techniques of stochastic approximation theory via a new convergence theorem. The theorem establishes a general class of convergent algorithms to which both TD( ) and Q-learning belong.}
}
\stopverb}