% ["references"]
\title{Monte Carlo Tree Search With Reinforcement Learning for Motion Planning}
\date{2020-09}
\author{Philippe Weingertner}\author{Minnie Ho}\author{Andrey Timofeev}\author{SÃ©bastien Aubert}\author{Guillermo Pita-Gil}
\taxon{Reference}
\meta{doi}{10.1109/ITSC45102.2020.9294697}
\meta{bibtex}{\startverb
@inproceedings{weingertnerMonteCarloTree2020,
 title = {Monte {{Carlo Tree Search With Reinforcement Learning}} for {{Motion Planning}}},
 author = {Weingertner, Philippe and Ho, Minnie and Timofeev, Andrey and Aubert, S{\'e}bastien and {Pita-Gil}, Guillermo},
 year = {2020},
 doi = {10.1109/ITSC45102.2020.9294697},
 urldate = {2025-03-19},
 booktitle = {2020 {{IEEE}} 23rd {{International Conference}} on {{Intelligent Transportation Systems}} ({{ITSC}})},
 pages = {1--7},
 file = {/home/kellen/Zotero/storage/YRS3JGCL/Weingertner et al. - 2020 - Monte Carlo Tree Search With Reinforcement Learning for Motion Planning.pdf;/home/kellen/Zotero/storage/K56QQ2MD/9294697.html},
 keywords = {Acceleration,Complexity theory,Dynamics,Planning,Real-time systems,Safety,Search problems},
 abstract = {Motion planning for an autonomous vehicle is most challenging for scenarios such as large, multi-lane, and unsignalized intersections in the presence of dense traffic. In such situations, the motion planner has to deal with multiple crossing-points to reach an objective in a safe, comfortable, and efficient way. In addition, motion planning challenges include real-time computation and scalability to complex scenes with many objects and different road geometries. In this work, we propose a motion planning system addressing these challenges. We enable real-time applicability of a Monte Carlo Tree Search algorithm with a deep-learning heuristic. We learn a fast evaluation function from accurate, but non real-time models. While using Deep Reinforcement Learning techniques we maintain a clear separation between making predictions and making decisions. We reduce the complexity of the search model and benchmark the proposed agent against multiple methods: rules-based, MCTS, A\textsuperscript{*} search, deep learning, and Model Predictive Control. We show that our agent outperforms these other agents in a variety of challenging scenarios, where we benchmark safety, comfort and efficiency metrics.},
 month = {September}
}
\stopverb}