% ["refs"]
\title{Epistemic Neural Networks}
\author/literal{Ian Osband}\author/literal{Zheng Wen}\author/literal{Seyed Mohammad Asghari}\author/literal{Vikranth Dwaracherla}\author/literal{Morteza Ibrahimi}\author/literal{Xiuyuan Lu}\author/literal{Benjamin Van Roy}
\taxon{Reference}
\meta{bibtex}{\startverb
@article{osbandEpistemicNeuralNetworks,
 title = {Epistemic {{Neural Networks}}},
 author = {Osband, Ian and Wen, Zheng and Asghari, Seyed Mohammad and Dwaracherla, Vikranth and Ibrahimi, Morteza and Lu, Xiuyuan and Roy, Benjamin Van},
 file = {/home/kellen/Downloads/pdfs/storage/X6XUW5KK/Osband et al. - Epistemic Neural Networks.pdf},
 langid = {english},
 abstract = {Intelligent agents need to know what they don't know, and this capability can be evaluated through the quality of joint predictions. In principle, ensemble methods can produce effective joint predictions, but the compute costs are prohibitive for large models. We introduce the epinet: an architecture that can supplement any conventional neural network, including large pretrained models, and can be trained with modest incremental computation to estimate uncertainty. With an epinet, conventional neural networks outperform large ensembles of hundreds or more particles, and use orders of magnitude less computation. The epinet does not fit the traditional framework of Bayesian neural networks, so we introduce the epistemic neural network (ENN) as a general interface for models that generate joint predictions.}
}
\stopverb}