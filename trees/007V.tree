
\import{base-macros}
\date{2025-06-23T03:40:22Z}
\author{kellenkanarios}
\title{[[007U]] (1/66): [TPE](arpaci2018operating) Processes}
\section{The Abstraction}{
\p{\em{A process} consists of a few primary components
\ol{
  \li{\strong{Memory}: each process requires its own portion of memory for (i) to store the instructions of the program to execute and (ii) for the memory required by the calling program. This is referred to as the \em{address space}.}
  \li{\strong{Registers}: for those familiar with computers, instructions typically deal with registers, where information is loaded from memory into registers to perform computation. Additionally, there are special registers reserved for certain mechanisms i.e.
  \ul{
    \li{\strong{Program Counter (PC)}: This register is in charge of telling us what instruction we are currently on in the executing program.}
    \li{\strong{Stack and Frame Pointer:} Used to manage where we currently are on the stack.}
  }
  }
}
}
}
\section{Process API}{
  \p{In order to implement a process, one must support each of the following operations}
  \ol{
    \li{
\strong{Create:} \p{The operating system must implement a mechanism to create a process. This consists of loading the program from disk, initializing memory (i.e. stack and heap), and jumping to \code{main} (typically).}
    }
\remark{
The stack is allocated up front and does not change. However, typically a small amount of memory is allocated for the heap and it grows via \code{malloc}. This is non-trivial because if \code{malloc} is called without available heap memory then memory must be allocated by the OS. I need to look into [how](https://gee.cs.oswego.edu/dl/html/malloc.html) this is done more.
}
\remark{
  The OS will also initialize the parameters to \code{main} i.e. \code{argc} or \code{argv}.
}
    \li{
\strong{Destroy:} Clearly, if a process is misbehaved or the user just does not want it to run any longer, there must be some mechanism to \em{kill} the process.
      }
    \li{ \strong{Wait:} In the case of dependencies (piping?), it may be useful to wait for a process to complete.
      }
    \li{
\strong{Miscellaneous Control:} The example provided in the book is to \em{suspend} a process.
      }
    \li{
\strong{Status:} It is helpful to be able to get information about running processes.
    }
  }
\p{There are also process \em{states}. These states are \strong{running}, \strong{ready}, and \strong{blocked}. These states are pretty self-explanatory.
  }
}
\section{Data Structures}{
  \p{It seems throughout the book we will be seeing implementation examples from the smaller [xv6](https://github.com/mit-pdos/xv6-public) OS.}
  \remark{
  In addition to the process implementation below, there is also a data structure that must keep track of all the processes. This is the \strong{process list} or \strong{process control block}.
  }
\p{
  \pre\verb<<<|
// the registers xv6 will save and restore
// to stop and subsequently restart a process
struct context {
  int eip;
  int esp;
  int ebx;
  int ecx;
  int edx;
  int esi;
  int edi;
  int ebp;
};
// the different states a process can be in
enum proc_state { UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE };
// the information xv6 tracks about each process
// including its register context and state
struct proc {
  char *mem; // Start of process memory
  uint sz; // Size of process memory
  char *kstack; // Bottom of kernel stack for this process
  enum proc_state state; // Process state
  int pid; // Process ID
  struct proc *parent; // Parent process
  void *chan; // If non-zero, sleeping on chan
  int killed; // If non-zero, have been killed
  struct file *ofile[NOFILE]; // Open files
  struct inode *cwd; // Current directory
  struct context context; // Switch here to run process
  struct trapframe *tf; // Trap frame for the current interrupt
};
  <<<
  }
}

\scope{
  \put\transclude/expanded{false}
\section{Homework}{
  \ol{
    \li{Run \code{process.py} with the flags \code{-l 5:100, 5:100}. What should the CPU utilization be?
    \answer{The flags correspond to running two processes each with #{5} instructions where each instruction has probability one of using the CPU. The output from the program is 
    \pre\verb<<<|
  Process 0
    cpu
    cpu
    cpu
    cpu
    cpu

  Process 1
    cpu
    cpu
    cpu
    cpu
    cpu
    <<<
    with this, we can conclude that the utilization is 100\%. We will execute one instruction for the first process until it completes, then the five instructions of the next process. If both are waiting on IO, then I do not think this would be the case? 
    }
    \solution{
    Using the solution flags \code{-cp}, there is 100\% utilization. 
    }
  }
    \li{Run \code{process.py} with the flags \code{-l 4:100, 1:0}. How long does it take to complete both processes?
    \answer{The flags correspond to running one process with #{4} instructions with each instruction having probability one of using the CPU and one process with one instruction that uses the IO. The output from the program is 
    \pre\verb<<<|
Process 0
  cpu
  cpu
  cpu
  cpu

Process 1
  io
  io_done
    <<<
It will take #{4 + \text{time of IO}}. Since the process with #{4} non-IO-dependent instructions will run each of those instructions and then the next process will begin which must wait for the entire duration of IO.
    }
    \solution{Using the \code{-cp} flags it takes #{11} timesteps to complete which is #{\approx 4 + \text{time of IO}}.
  }
    }
\li{
Now switch the order of the processes: \code{./process-run.py -l
1:0,4:100}. What happens now? Does switching the order mat-
ter? Why?
  \answer{
The output of the code is
    \pre\verb<<<|
Process 0
  io
  io_done

Process 1
  cpu
  cpu
  cpu
  cpu
    <<<
    Depending on the time of IO (\code{the -L flag}), it should take #{\max(5, 1 + \text{time IO})}. Switching the order does matter because we can run the CPU instructions while waiting for non-blocking IO. This motivates the idea of scheduling.
  }
  \solution{
    It only takes #{7} timesteps because we are able to perform the IO operations off the CPU as expected.
  }
  }
  \li{
Weâ€™ll now explore some of the other flags. One important flag is \code{-S}, which determines how the system reacts when a process issues an I/O. With the flag set to \code{SWITCH_ON_END}, the system will NOT switch to another process while one is doing I/O, instead waiting until the process is completely finished. What happens when you run the following two processes, one doing I/O and the other doing CPU work? (\code{-l 1:0,4:100 -c -S SWITCH_ON_END})
\answer{
  The output of the code is:
\pre\verb<<<|
Time        PID: 0        PID: 1           CPU           IOs
  1         RUN:io         READY             1          
  2        BLOCKED         READY                           1
  3        BLOCKED         READY                           1
  4        BLOCKED         READY                           1
  5        BLOCKED         READY                           1
  6        BLOCKED         READY                           1
  7*   RUN:io_done         READY             1          
  8           DONE       RUN:cpu             1          
  9           DONE       RUN:cpu             1          
 10           DONE       RUN:cpu             1          
 11           DONE       RUN:cpu             1          
<<<
As expected, it runs the IO process, blocking the CPU process until it is completed.
}
    }
    \li{Now, run the same processes, but with the switching behavior set
to switch to another process whenever one is \code{WAITING} for I/O (\code{-l 1:0,4:100 -c -S SWITCH ON IO}). What happens now? Use \code{-c}
and \code{-p} to confirm that you are right}
\answer{
  I assume that at timestep #{1} we will still \code{RUN:io}. However, we will then switch the \code{PID: 1} for the next #{4} timesteps until it is completed. After one additional \code{BLOCKED} timestep, we will run \code{RUN:io_done} and complete both processes. 
}
\solution{
  The output of the code is:
  \pre\verb<<<|
Time        PID: 0        PID: 1           CPU           IOs
  1         RUN:io         READY             1          
  2        BLOCKED       RUN:cpu             1             1
  3        BLOCKED       RUN:cpu             1             1
  4        BLOCKED       RUN:cpu             1             1
  5        BLOCKED       RUN:cpu             1             1
  6        BLOCKED          DONE                           1
  7*   RUN:io_done          DONE             1          
  <<<
}
\li{
One other important behavior is what to do when an I/O completes. With -I IO RUN LATER, when an I/O completes, the process that issued it is not necessarily run right away; rather, whatever was running at the time keeps running. What happens when you run this combination of processes? (\code{./process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH ON IO -I IO RUN LATER -c -p}) Are system resources being effectively utilized?
\answer{
  The resources are not efficiently utilized because we end up waiting until all of our CPU-bound processes finish before returning to the IO-bound process, which calls another \code{IO:run} and we do not get any concurrency benefit.
}
\solution{
  The code output is pretty long but the end output is
  \pre\verb<<<|
Stats: Total Time 31
Stats: CPU Busy 21 (67.74%)
Stats: IO Busy  15 (48.39%)
  <<<
}
}
\li{
Now run the same processes, but with \code{-I IO RUN IMMEDIATE} set, which immediately runs the process that issued the I/O. How does this behavior differ? Why might running a process that just completed an I/O again be a good idea?
\answer{
  The behavior differs by returning to the IO-bound process, which can then immediately call the next \code{IO:run} before returning access to the CPU-bound processes, improving concurrency. In an attempt to predict the next IO call, it might be a good idea to run the process that just completed IO because it is more likely to make another IO call.
}
\solution{
  The corresponding statistics are
  \pre\verb<<<|
Stats: Total Time 21
Stats: CPU Busy 21 (100.00%)
Stats: IO Busy  15 (71.43%)
  <<<
}
}
\li{
Now run with some randomly generated processes, e.g., \code{-s 1 -l
3:50,3:50, -s 2 -l 3:50,3:50, -s 3 -l 3:50,3:50}. See
if you can predict how the trace will turn out. What happens when
you use \code{-I IO RUN IMMEDIATE} vs. \code{-I IO RUN LATER}? What hap-
pens when you use \code{-S SWITCH ON IO} vs. \code{-S SWITCH ON END}?
\answer{
  Since each instruction has a 50\% chance of being CPU or I/O, I do not think there will be much benefit to \code{IO_RUN_LATER} vs. \code{IO_RUN_IMMEDIATE}. However, I believe it will be crucial to enable \code{-S SWITCH_ON_IO} over \code{-S SWITCH_ON_END} as the number of processes grow because we should always have waiting CPU instructions to run. In the case of two processes, we still may not improve that much because they will likely both be IO-bound at some point.
}
\solution{
  For \code{-s 1} (aka the seed), the observed performance between \code{IO_RUN_IMMEDIATE} and \code{IO_RUN_LATER} is the same. However, we do observe an improvement on both IO and CPU usage when we enable \code{SWITCH_ON_IO}.
}
}
    }
  }
}
